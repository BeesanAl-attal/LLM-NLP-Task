{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2578f874-4118-4169-a78c-333550851d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\msi\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using the processed data that we worked on in task 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16033f0-e7b6-4383-8951-26728dbbe730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load & Preprocess Dataset\n",
    "# Load DataFrame\n",
    "processed_data_file = 'processed_reviews.pkl' # change the file path if needed\n",
    "df = pd.read_pickle(processed_data_file)\n",
    "\n",
    "# Tokenization and Padding\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7556ca23-cac2-4aea-9ffc-4ca16006e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds = SentimentDataset(X_train, y_train)\n",
    "val_ds = SentimentDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1112d140-0e26-491e-a027-c9b4e7801eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model \n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        h = torch.cat((h_n[0], h_n[1]), dim=1)\n",
    "        out = self.fc(h)\n",
    "        return self.sigmoid(out).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b7cf485-ac24-414a-b752-18f1b4cfa3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Using device: cuda\n",
      "✅ GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "Model is on device: cuda:0\n",
      "Epoch 1, Loss: 0.4620\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 2, Loss: 0.2937\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 3, Loss: 0.2195\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 4, Loss: 0.1622\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 5, Loss: 0.1114\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 6, Loss: 0.0700\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 7, Loss: 0.0477\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 8, Loss: 0.0299\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 9, Loss: 0.0282\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n",
      "Epoch 10, Loss: 0.0244\n",
      "GPU Memory Allocated: 43.05 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training loop utilizing the gpu device \n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n✅ Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"✅ GPU name: {torch.cuda.get_device_name(0)}\\n\")\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = BiLSTMClassifier(vocab_size=max_words, embed_dim=128, hidden_dim=64).to(device)\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Optional: Show GPU memory usage\n",
    "    if device.type == \"cuda\":\n",
    "        mem_alloc = torch.cuda.memory_allocated() / 1024**2\n",
    "        print(f\"GPU Memory Allocated: {mem_alloc:.2f} MB\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8e9b3cb-f321-43f6-a687-1d9c46ef8442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8666\n",
      "Precision: 0.8759\n",
      "Recall: 0.8575\n",
      "Accuracy: 0.8670\n",
      "Confusion Matrix:\n",
      "[[4349  612]\n",
      " [ 718 4321]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "model.eval()\n",
    "y_preds, y_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        y_preds.extend(outputs.cpu().numpy())\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "y_pred_bin = (np.array(y_preds) > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred_bin)\n",
    "precision = precision_score(y_true, y_pred_bin)\n",
    "recall = recall_score(y_true, y_pred_bin)\n",
    "accuracy = accuracy_score(y_true, y_pred_bin)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_bin)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0eb787d6-dced-4cd9-ad8a-d90ca24f24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"bilstm_sentiment_model_raw.pt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Task1",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
