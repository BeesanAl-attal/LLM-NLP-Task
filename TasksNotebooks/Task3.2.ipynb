{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b2ee2a-7598-496a-803a-f2745e4ca1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0238c187-868a-460e-b010-4118ce65b0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\msi\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, confusion_matrix\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0724ed8-7751-446f-8f4f-976dc482b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and preprocess, the un-processed version of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b1f311-7d76-46da-ac7b-168f63425a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DataFrame\n",
    "file_path = \"archive (2).zip\" # change to the dataset file path\n",
    "df = pd.read_csv(file_path, compression='zip')\n",
    "\n",
    "# Tokenization and Padding\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])\n",
    "X = pad_sequences(sequences, maxlen=max_len)\n",
    "y = df['sentiment'].apply(lambda x: 1 if x == 'positive' else 0).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eca3d70-598b-4129-8632-a2a573f15c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de300dc-2ab5-4b75-86b4-10ae73d4bd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.long)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds = SentimentDataset(X_train, y_train)\n",
    "val_ds = SentimentDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d5a5d-5b75-4551-8159-fb3805ffee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-Directional lstm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd781d10-0c28-409a-8aaa-b023664b2407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        h = torch.cat((h_n[0], h_n[1]), dim=1)\n",
    "        out = self.fc(h)\n",
    "        return self.sigmoid(out).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b4e76-2f87-4bdb-905b-894547ce5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db746a96-a26a-4810-ab1f-31ed703b382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Using device: cuda\n",
      "✅ GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "\n",
      "Model is on device: cuda:0\n",
      "Epoch 1, Loss: 0.5211\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 2, Loss: 0.3349\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 3, Loss: 0.2533\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 4, Loss: 0.1917\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 5, Loss: 0.1328\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 6, Loss: 0.0836\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 7, Loss: 0.0516\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 8, Loss: 0.0321\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 9, Loss: 0.0213\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n",
      "Epoch 10, Loss: 0.0187\n",
      "GPU Memory Allocated: 47.84 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"\\n✅ Using device: {device}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"✅ GPU name: {torch.cuda.get_device_name(0)}\\n\")\n",
    "\n",
    "# Model, Loss, Optimizer\n",
    "model = BiLSTMClassifier(vocab_size=max_words, embed_dim=128, hidden_dim=64).to(device)\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Optional: Show GPU memory usage\n",
    "    if device.type == \"cuda\":\n",
    "        mem_alloc = torch.cuda.memory_allocated() / 1024**2\n",
    "        print(f\"GPU Memory Allocated: {mem_alloc:.2f} MB\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eba541c-a561-4bd1-b432-13e2c6c2c7cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52604b3e-b73b-4e9c-ba27-7be541912d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8577\n",
      "Precision: 0.8673\n",
      "Recall: 0.8484\n",
      "Accuracy: 0.8582\n",
      "Confusion Matrix:\n",
      "[[4307  654]\n",
      " [ 764 4275]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation \n",
    "model.eval()\n",
    "y_preds, y_true = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        y_preds.extend(outputs.cpu().numpy())\n",
    "        y_true.extend(labels.numpy())\n",
    "\n",
    "y_pred_bin = (np.array(y_preds) > 0.5).astype(int)\n",
    "\n",
    "f1 = f1_score(y_true, y_pred_bin)\n",
    "precision = precision_score(y_true, y_pred_bin)\n",
    "recall = recall_score(y_true, y_pred_bin)\n",
    "accuracy = accuracy_score(y_true, y_pred_bin)\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_bin)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b80fa53-d2ae-4cc4-8fad-150bb270d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"bilstm_sentiment_model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Task1",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
