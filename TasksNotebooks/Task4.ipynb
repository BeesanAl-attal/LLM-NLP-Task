{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4db759-f9be-48a6-8900-7b8860f6eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4a9a9a-58ee-4511-9015-a22ee277de5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56cef136-00ae-4b8f-ab06-308a88189963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Set up device utilize device gpu \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85b18c9-0aac-4b71-b917-87174a0ea761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026746cb-e87b-4475-8eb1-51f1eaefe328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msi\\anaconda3\\envs\\nlp_env\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\msi\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17ab55c8-c063-4257-b021-7c39056436d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra padding to avoid warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f5716fd-6d35-4406-a8cd-ff34e1682a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4156f-c7ef-4485-8371-3966d79ac40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving the model to the device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d16346-a788-4dea-b78d-5bb05133f11c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b397e45f-4896-4e5e-9a47-1e6bc6db7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples retrieved from the dataset \n",
    "examples = [\n",
    "    # POSITIVE\n",
    "    (\n",
    "        \"Think wonderful way spend time hot summer weekend sit air condition theater watch lighthearted comedy plot simplistic dialogue witty character likable even well bread suspect serial killer may disappoint realize match point 2 risk addiction think proof woody allen still fully control style many us grow lovethis i d laugh one woodys comedy year dare say decade I ve never impress scarlet johanson manage tone sexy image jump right average spirited young womanthis may crown jewel career witty devil wear prada interesting superman great comedy go see friend\",\n",
    "        \"Positive\"\n",
    "    ),\n",
    "    (\n",
    "        \"Wonderful little production filming technique unassume oldtimebbc fashion give comfort sometimes discomforte sense realism entire piece actor extremely well choose michael sheen get polari voice pat truly see seamless editing guide reference williams diary entry well worth watching terrificly write perform piece masterful production one great master comedy life realism really come home little thing fantasy guard rather use traditional dream technique remain solid disappear play knowledge sense particularly scene concern orton halliwell set particularly flat halliwell mural decorate every surface terribly well do\",\n",
    "        \"Positive\"\n",
    "    ),\n",
    "    (\n",
    "        \"One reviewer mention watch 1 oz episode you ll hook right exactly happen methe first thing strike oz brutality unflinche scene violence set right word go trust show faint hearted timid show pull punch regard drug sex violence hardcore classic use wordit call oz nickname give oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inward privacy high agenda em city home manyaryan muslim gangstas latinos christians italians irish moreso scuffle death stare dodgy dealing shady agreement never far awayi would say main appeal show due fact go show would not dare forget pretty picture paint mainstream audience forget charm forget romanceoz do not mess around first episode ever see strike nasty surreal could not say ready watch develop taste oz get accustomed high level graphic violence violence injustice crook guard who ll sell nickel inmate who ll kill order get away well mannered middle class inmate turn prison bitch due lack street skill prison experience watch oz may become comfortable uncomfortable viewingthat get touch dark side\",\n",
    "        \"Positive\"\n",
    "    ),\n",
    "    # NEGATIVE\n",
    "    (\n",
    "        \"Basically there s family little boy jake think there s zombie closet parent fight timethis movie slow soap opera suddenly jake decide become rambo kill zombieok first you re go make film must decide thriller drama drama movie watchable parent divorce argue like real life jake closet totally ruin film expect see boogeyman similar movie instead watch drama meaningless thriller spots3 10 well play parent descent dialog shot jake ignore show\",\n",
    "        \"Negative\"\n",
    "    ),\n",
    "    (\n",
    "        \"Amazing fresh innovative idea 70 first air first 7 8 year brilliant thing drop 1990 show really funny anymore continue decline complete waste time todayit truly disgraceful far show fall write painfully bad performance almost bad mildly entertaining respite guesthost show probably would not still air find hard believe creator handselecte original cast also choose band hack follow one recognize brilliance see fit replace mediocrity feel must give 2 star respect original cast make show huge success show awful can not believe still air\",\n",
    "        \"Negative\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "954f2f08-37b2-4956-9676-ab6f147391c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt builder\n",
    "def create_prompt(review, num_shots=1):\n",
    "    selected = random.sample(examples, num_shots)\n",
    "    prompt = \"\"\n",
    "    for ex_text, label in selected:\n",
    "        prompt += f\"Review: {ex_text}\\nSentiment: {label}\\n\\n\"\n",
    "    prompt += f\"Review: {review}\\nSentiment:\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "774fcaac-194f-470b-94d6-186f47febf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier\n",
    "def classify_sentiment(review, num_shots=1, max_new_tokens=10):\n",
    "    prompt = create_prompt(review, num_shots)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    match = re.search(r\"Sentiment:\\s*(Positive|Negative)\", generated_text, re.IGNORECASE)\n",
    "    return match.group(1).capitalize() if match else \"Invalid Output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf82af7a-af25-4e83-b567-c696d08ecf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a new review to classify:\n",
      " the movie sucks \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-shot Prediction: Positive\n",
      "2-shot Prediction: Positive\n",
      "3-shot Prediction: Negative\n"
     ]
    }
   ],
   "source": [
    "# Main interactive loop\n",
    "if __name__ == \"__main__\":\n",
    "    review_input = input(\"Enter a new review to classify:\\n\")\n",
    "    for shots in [1, 2, 3]:\n",
    "        result = classify_sentiment(review_input, num_shots=shots)\n",
    "        print(f\"{shots}-shot Prediction: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Task1",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
