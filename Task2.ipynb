{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae71dd-6e05-47b7-a781-36b9288ecd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be1662dd-d0bc-48ed-827e-685313bc3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import joblib\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824381d-64bc-441c-a98d-10d0045f7fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the processed data file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20c7968-8287-4cf5-8ceb-29e6e3ded9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewer mention watch 1 oz episode you ll...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there s family little boy jake think...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewer mention watch 1 oz episode you ll...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  think wonderful way spend time hot summer week...  positive\n",
       "3  basically there s family little boy jake think...  negative\n",
       "4  petter matteis love time money visually stunni...  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pickle_file_path = \"processed_reviews.pkl\" # Change the path\n",
    "movie_review = pd.read_pickle(pickle_file_path)\n",
    "movie_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cef49023-710e-4670-9b58-5f1e0d821f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mulitple dataframes for different experimentations\n",
    "df_exp1 = movie_review.copy()\n",
    "df_exp2 = movie_review.copy()\n",
    "df_exp3 = movie_review.copy()\n",
    "df_exp4 = movie_review.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2494f-b66f-4ea2-9a5a-34abeea3a704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8ae2fab-4ec7-44d2-95cd-b19597d2b348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49577</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>love today show variety solely cooking would g...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49577         2\n",
       "top     love today show variety solely cooking would g...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate data --> ignored, small percentage\n",
    "movie_review.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16262ae8-5d06-458b-925e-8c6b8e2b427e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment Count \n",
    "# Balanced data \n",
    "movie_review['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b461b-e275-493c-b1a9-b503038e9ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentation One : Dataframe used movie_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de71aed7-906f-4531-b70a-e6f9b69bcca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Vectorization using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(movie_review['review'])\n",
    "\n",
    "# Label encoding \n",
    "y = movie_review['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split the data to train  test 80% 20%\n",
    "# using stratified spliting to avoid bias\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a484acac-6968-4458-9fe5-1b85256d8f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 204508) (10000, 204508)\n",
      "sentiment\n",
      "1    20000\n",
      "0    20000\n",
      "Name: count, dtype: int64\n",
      "sentiment\n",
      "0    5000\n",
      "1    5000\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.8945\n"
     ]
    }
   ],
   "source": [
    "# Shape of the splits \n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# Check that the stratified split was done correctly \n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n",
    "\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\") # intial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "531bc899-48fa-4d85-bd35-d8bb11e24756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 0.1172\n",
      "FNR: 0.0938\n",
      "Confusion Matrix:\n",
      "[[4414  586]\n",
      " [ 469 4531]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      5000\n",
      "           1       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Full Evaluation \n",
    "# evaluate performance using accuaracy, f1 score, FPR, FNR\n",
    "# based on the result the model is decent yet needs more work\n",
    "y_pred = lr_model.predict(X_test)\n",
    "\n",
    "FPR = confusion_matrix(y_test, y_pred)[0, 1] / (confusion_matrix(y_test, y_pred)[0, 1] + confusion_matrix(y_test, y_pred)[0, 0])\n",
    "FNR = confusion_matrix(y_test, y_pred)[1, 0] / (confusion_matrix(y_test, y_pred)[1, 0] + confusion_matrix(y_test, y_pred)[1, 1])\n",
    "\n",
    "print(f\"FPR: {FPR}\")\n",
    "print(f\"FNR: {FNR}\")\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Classification repp\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6951ea-08ed-406a-b989-a14e9b9bc0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model weights Exp 1\n",
    "joblib.dump(lr_model, 'logistic_regression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e243289-2a4d-4e66-9261-1ecc76281f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimentation Two: Dataframe used df_exp2 (all in one block)\n",
    "# slightly better resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1142c5d8-25cc-4f84-a819-6f95eab97416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 0.1176\n",
      "FNR: 0.091\n",
      "Confusion Matrix:\n",
      "[[4412  588]\n",
      " [ 455 4545]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89      5000\n",
      "           1       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and Vectorization using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X2 = tfidf_vectorizer.fit_transform(df_exp2['review'])\n",
    "\n",
    "# Label encoding \n",
    "y2 = df_exp2['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split the data to train/test 80%/20%\n",
    "# using stratified splitting to avoid bias\n",
    "\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(\n",
    "    X2, y2, test_size=0.2, random_state=42, stratify=y2\n",
    ")\n",
    "\n",
    "# Train logistic regression\n",
    "\n",
    "\n",
    "lr_model2 = LogisticRegression()\n",
    "lr_model2.fit(X2_train, y2_train)\n",
    "\n",
    "# Evaluate performance using accuracy, F1 score, FPR, FNR\n",
    "\n",
    "y2_pred = lr_model2.predict(X2_test)\n",
    "\n",
    "# Compute confusion matrix once\n",
    "cm2 = confusion_matrix(y2_test, y2_pred)\n",
    "FPR2 = cm2[0, 1] / (cm2[0, 1] + cm2[0, 0])\n",
    "FNR2 = cm2[1, 0] / (cm2[1, 0] + cm2[1, 1])\n",
    "\n",
    "print(f\"FPR: {FPR2}\")\n",
    "print(f\"FNR: {FNR2}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm2)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y2_test, y2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71db3a2d-caa5-4244-8b73-21001810282d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model2.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_model2, 'logistic_regression_model2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1717dd8f-b261-434b-9dad-1f84cd5964b9",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Experiment Three : dataframe used df_exp1 (all in one bloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63c71956-67aa-43cf-957e-0b5d82ed63f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 0.1176\n",
      "FNR: 0.091\n",
      "Confusion Matrix:\n",
      "[[4412  588]\n",
      " [ 455 4545]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89      5000\n",
      "           1       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and Vectorization using TF-IDF\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))  # the grams for combining words, two in this case\n",
    "X3 = tfidf_vectorizer.fit_transform(df_exp1['review'])\n",
    "\n",
    "# Label encoding \n",
    "y3 = df_exp1['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split the data to train/test 80%/20%\n",
    "# using stratified splitting to avoid bias\n",
    "\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(\n",
    "    X3, y3, test_size=0.2, random_state=42, stratify=y3\n",
    ")\n",
    "\n",
    "# Train logistic regression\n",
    "\n",
    "\n",
    "lr_model3 = LogisticRegression(penalty='l2', max_iter=500, random_state=4)\n",
    "lr_model3.fit(X3_train, y3_train)\n",
    "\n",
    "# Evaluate performance using accuracy, F1 score, FPR, FNR\n",
    "\n",
    "\n",
    "y3_pred = lr_model3.predict(X3_test)\n",
    "\n",
    "# Compute confusion matrix once\n",
    "cm3 = confusion_matrix(y3_test, y3_pred)\n",
    "FPR3 = cm3[0, 1] / (cm3[0, 1] + cm3[0, 0])\n",
    "FNR3 = cm3[1, 0] / (cm3[1, 0] + cm3[1, 1])\n",
    "\n",
    "print(f\"FPR: {FPR3}\")\n",
    "print(f\"FNR: {FNR3}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm3)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y3_test, y3_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f75728f-8e38-4c0a-a1be-ff7b03c6492b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model3.pkl']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_model2, 'logistic_regression_model3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243bd928-a5be-49d1-a4ac-c1f13f2ddf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment four: dataframe used df_exp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42d3d19a-e3a4-4d9e-8f7c-466836abe9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
      "Best Cross-Validated F1 Score: 0.8914497009828711\n"
     ]
    }
   ],
   "source": [
    "# Tokenization and Vectorization using TF-IDF\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "X4 = tfidf_vectorizer.fit_transform(df_exp4['review'])\n",
    "\n",
    "# Label encoding\n",
    "y4 = df_exp4['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Train/test split with stratification\n",
    "\n",
    "\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(\n",
    "    X4, y4, test_size=0.2, random_state=42, stratify=y4\n",
    ")\n",
    "\n",
    "# Trying Grid Search to improve the results\n",
    "\n",
    "\n",
    "param_grid4 = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l2'],  # we want to avoid sparsity and this matches TF-IDF behavior\n",
    "    'solver': ['saga']\n",
    "}\n",
    "\n",
    "grid4 = GridSearchCV(\n",
    "    LogisticRegression(max_iter=1000),  # increased max_iter\n",
    "    param_grid4,\n",
    "    cv=5,               # 5-fold cross-validation\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid4.fit(X4_train, y4_train)\n",
    "lr_model4 = grid4.best_estimator_\n",
    "\n",
    "print(\"Best Parameters:\", grid4.best_params_)\n",
    "print(\"Best Cross-Validated F1 Score:\", grid4.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecde00d5-c639-4ece-bc0d-40415992ea1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR: 0.1182\n",
      "FNR: 0.0902\n",
      "Confusion Matrix:\n",
      "[[4409  591]\n",
      " [ 451 4549]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89      5000\n",
      "           1       0.89      0.91      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Accuracy: 0.8958\n",
      "F1 Score: 0.8972386587771203\n"
     ]
    }
   ],
   "source": [
    "y4_pred = lr_model4.predict(X4_test)\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm4 = confusion_matrix(y4_test, y4_pred)\n",
    "FPR4 = cm4[0, 1] / (cm4[0, 1] + cm4[0, 0])\n",
    "FNR4 = cm4[1, 0] / (cm4[1, 0] + cm4[1, 1])\n",
    "\n",
    "print(f\"FPR: {FPR4}\")\n",
    "print(f\"FNR: {FNR4}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm4)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y4_test, y4_pred))\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y4_test, y4_pred))\n",
    "print(\"F1 Score:\", f1_score(y4_test, y4_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21f1daf2-227e-4aa6-9c33-1c8a30e2e1fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_regression_model4.pkl']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(lr_model2, 'logistic_regression_model4.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Task1",
   "language": "python",
   "name": "nlp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
